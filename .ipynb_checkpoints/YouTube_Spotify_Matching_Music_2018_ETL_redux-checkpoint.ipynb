{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube & Spotify Top Music Artists From 2018\n",
    "---\n",
    "\n",
    "### SCOPE:\n",
    "#### - Extracted, transformed, and loaded up YouTube's Top Trending Videos from December 2017 thru May 2018 for their videos categorized as music only, and created an \"Artist\" column to enable joining with Spotify's Top 100 Songs of 2018. Both dataframes were loaded into MySQL.\n",
    "\n",
    "\n",
    "### PURPOSE:\n",
    "#### - I choose this project because I'm a avid listener and a huge music and concert goer, and wanted to work with data that I was familiar with.\n",
    "\n",
    "### Data Sources:\n",
    "#### - https://www.kaggle.com/datasnaek/youtube-new (this is an updated link, whereas I used an older version of this file, which is attached in the resources)\n",
    "#### - https://www.kaggle.com/nadintamer/top-spotify-tracks-of-2018\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies 1/2:\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import simplejson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1) SQL Alchemy setup and built a search, create, and drop database function to set up loading phase after extraction and transformation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies 2/2:\n",
    "from sqlalchemy import create_engine, Column, Integer, String, join, Date, Table, MetaData\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy_utils import database_exists, create_database, drop_database, has_index\n",
    "import pymysql\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rds_connection_string = \"<inser user name>:<insert password>@127.0.0.1/customer_db\"\n",
    "rds_connection_string = \"root:PASSWORD@127.0.0.1/\" #youtube_spotify_2018_db\"\n",
    "\n",
    "# Can set up an input for the db_name later (optional)\n",
    "#db_name = input(\"What database would you like to search for?\")\n",
    "db_name = 'youtube_spotify_2018_db2'\n",
    "\n",
    "# Setup engine connection string\n",
    "#engine = create_engine(f'mysql://{rds_connection_string}{db_name}?charset=utf8')\n",
    "engine = create_engine(f'mysql://{rds_connection_string}{db_name}?charset=utf8', echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function incorproating SQL Alchemy to search, create, and or drop a database:\n",
    "def search_create_drop_db(db_name):\n",
    "    #db_exist = database_exists(f'mysql://{rds_connection_string}youtube_spotify_2018_db2')\n",
    "    db_exist = database_exists(f'mysql://{rds_connection_string}{db_name}')\n",
    "    db_url = f'mysql://{rds_connection_string}{db_name}'\n",
    "    if db_exist == True:\n",
    "        drop_table_y_or_n = input(f'\"{db_name}\" database already exists in MySQL. Do you want you drop the table? Enter exactly: \"y\" or \"n\".  ')\n",
    "        if drop_table_y_or_n == 'y':\n",
    "            drop_database(db_url)\n",
    "            print(f\"Database {db_name} was dropped\")\n",
    "            create_new_db = input(f\"Do you want to create another database called: {db_name}?  \")\n",
    "            if create_new_db == 'y':\n",
    "                create_database(db_url)\n",
    "                return(f\"The database {db_name} was created. Next You will need to create tables for this database.  \")\n",
    "            else:\n",
    "                return(\"No database was created. Goodbye!  \")\n",
    "        else:\n",
    "            return(\"The database exists. No action was taken. Goodbye!  \")\n",
    "    else:\n",
    "        create_database(db_url)\n",
    "        return(f\"The queried database did not exist, and was created as: {db_name} .  \")\n",
    "\n",
    "search_create_drop_db(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create CLASSES / AKA tables 'blueprints' using python classes and sql alchemy:\n",
    "# # This would be useful say if I was to use SQL Alchemy to import a sqllite file into python\n",
    "\n",
    "# class yt_categories(Base):\n",
    "#     __tablename__ = 'yt_category_titles'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     category_title = Column(String(60))\n",
    "\n",
    "# class yt_statistics_data(Base):\n",
    "#     __tablename__ = 'yt_statistics'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     category_title = Column(String(60))\n",
    "#     trending_date = Column(Date, nullable=False)\n",
    "#     video_title = Column(String(200))\n",
    "#     channel_title = Column(String(100))\n",
    "#     category_id = Column(Integer)\n",
    "#     views = Column(Integer)\n",
    "#     likes = Column(Integer)\n",
    "#     dislikes = Column(Integer)\n",
    "#     view_count = Column(Integer)\n",
    "\n",
    "# class spotify_music_data(Base):\n",
    "#     __tablename__ = 'spotify_music'\n",
    "#     id = Column(Integer, primary_key=True)\n",
    "#     artist = Column(String(100))\n",
    "#     song_name = Column(String(200))\n",
    "#     spotify_unique_id = Column(String(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables 'blueprints' using python classes and sql alchemy:\n",
    "\n",
    "meta = MetaData()\n",
    "conn = engine.connect()\n",
    "\n",
    "yt_categories = Table(\n",
    "   'yt_categories', meta, \n",
    "   Column('category_id', Integer, primary_key = True), \n",
    "   Column('category_title', String)\n",
    ")\n",
    "\n",
    "yt_statistics = Table(\n",
    "   'yt_statistics', meta,\n",
    "   Column('id', Integer, primary_key = True),\n",
    "   Column('trending_date', Date, nullable=False),\n",
    "   Column('video_title', String),\n",
    "   Column('channel_title', String),\n",
    "   Column('category_id', Integer),\n",
    "   Column('views', Integer),\n",
    "   Column('likes', Integer),\n",
    "   Column('dislikes', Integer),\n",
    "   Column('comment_count', Integer)\n",
    ")\n",
    "\n",
    "spotify_2018top100_data = Table(\n",
    "   'spotify_2018top100_data', meta,\n",
    "   Column('Artist', String, primary_key = True),\n",
    "   Column('song_name', String),\n",
    "   Column('unique_id', String)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a) ETL on the \"YouTube Categories\" JSON dataset:\n",
    "### Extraction, transformation, load, and read using 2 methods from MySQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube data has two parts: 1) Categories information in JSON format\n",
    "                            # 2) Top Trending US YouTube Videos in a CSV file\n",
    "\n",
    "# Part 1) YouTube Categories are seperated in a json file\n",
    "yt_json_file = './resources/youtube_US_category_id.json'\n",
    "yt_rawjson_df = pd.read_json(yt_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the category id and category titles, and set them into a list\n",
    "\n",
    "# for i in yt_rawjson_df['items']:\n",
    "#     #print(i['id'])\n",
    "#     print(i['id'] + ' | ' + i['snippet']['title'])\n",
    "    \n",
    "\n",
    "category_id = [int(i['id']) for i in yt_rawjson_df['items']]\n",
    "category_title = [str(i['snippet']['title']) for i in yt_rawjson_df['items']]\n",
    "\n",
    "# Create a dataframe of the category id and title for later use\n",
    "category_id_title_df = pd.DataFrame({'category_id': category_id, 'category_title': category_title})\n",
    "category_id_title_df.head()\n",
    "category_id_title_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Dulplicates and Sort by category_title\n",
    "category_id_title_df.drop_duplicates(['category_id', 'category_title']).sort_values(by=['category_title'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category_id_title_df to MySQL with Pandas\n",
    "category_id_title_df.to_sql('yt_categories', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways in this notebook to pull the data directly from MySQL database\n",
    "# Method 1) Use SQL Alchemy Engine - Result: successfully reads from MySQL Database:\n",
    "engine.execute(\"SELECT * FROM yt_categories\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Method 2) Read from MySQL database using Pandas - Result: Success! - This method is a better setup for analysis.\n",
    "# The index column is automatically generated.\n",
    "yt_cat_df = pd.read_sql_query('SELECT * FROM yt_categories', con=engine)\n",
    "yt_cat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b) ETL on the \"YouTube Top Trending US Videos\" dataset:\n",
    "### Extraction, transformation, load, and read using 2 methods from MySQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1) is the YouTube Top US Videos in a CSV\n",
    "csv_file_yt = \"./resources/youtube_USvideos.csv\"\n",
    "yt_rawdata_df = pd.read_csv(csv_file_yt, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rows, count and datatypes\n",
    "yt_rawdata_df\n",
    "yt_rawdata_df['id'] = yt_rawdata_df.index\n",
    "yt_rawdata_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "yt_statistics_data_df = yt_rawdata_df.rename(columns={\n",
    "                                                \"title\":\"video_title\",\n",
    "                                                \"category_id\":\"category_id\"\n",
    "                                               })\n",
    "yt_statistics_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cells with Missing Information\n",
    "yt_statistics_data_df = yt_statistics_data_df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Dulplicates and Sort by Trending Date\n",
    "yt_statistics_data_df.drop_duplicates(['video_id', 'trending_date', 'video_title', 'channel_title', 'category_id', 'publish_time', 'views', 'likes', 'dislikes', 'comment_count']).sort_values(by=['trending_date'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unwanted Columns\n",
    "\n",
    "to_drop =['video_id', 'publish_time', 'tags', 'thumbnail_link', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed', 'description']\n",
    "\n",
    "yt_statistics_data_df.drop(to_drop, inplace=True, axis=1)\n",
    "yt_statistics_data_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize columns to match SQL Alchemy Table\n",
    "\n",
    "cols = yt_statistics_data_df.columns.tolist()\n",
    "cols = cols[-1:] + cols[0:-1]\n",
    "cols\n",
    "yt_statistics_data_df = yt_statistics_data_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replace the \".\" in Trending Date to \"-\"\n",
    "\n",
    "yt_statistics_data_df['trending_date'] = [x.replace(\".\",\"-\") for x in yt_statistics_data_df['trending_date']]\n",
    "yt_statistics_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulled up this dataframe verify exactly how \"Music\" was spelled for the following step:\n",
    "category_id_title_df['category_title'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used Pandas Merge aka (Join in Relational DB) Inner joined the Both YouTube Tables to find what Category_id 10 means:\n",
    "\n",
    "yt_merged_df = pd.merge(yt_statistics_data_df, category_id_title_df, how='inner', on='category_id',\n",
    "         left_index=False, right_index=False, sort=False)\n",
    "\n",
    "yt_musicdata_df = yt_merged_df[yt_merged_df['category_title']  == 'Music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only going to clean and focus on YT videos that are in the \"Music\" category_title:\n",
    "\n",
    "# Clean Channel Title Column to set up the MAIN LOOP\n",
    "\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"VEVO\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"vevo\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"Vevo\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"Official\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"official\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"OFFICIAL\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"You Tube Channel\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"Music\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\"music\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "yt_musicdata_df['channel_title'] = [x.replace(\" - Topic\",\"\") for x in yt_musicdata_df['channel_title']]\n",
    "\n",
    "yt_musicdata_df['channel_title'].replace(\"BackstreetBoys\",\"Backstreet Boys\")\n",
    "yt_musicdata_df['channel_title'].replace(\"CalumScott\",\"Calum Scott\")\n",
    "yt_musicdata_df['channel_title'].replace(\"TaylorSwift\",\"Taylor Swift\")\n",
    "yt_musicdata_df['channel_title'].replace(\"NickiMinajAt\",\"Nicki Minaj\")\n",
    "yt_musicdata_df['channel_title'].replace(\"FifthHarmony\",\"FifthHarmony\")\n",
    "yt_musicdata_df['channel_title'].replace(\"davematthewsband\",\"Dave Matthews Band\")\n",
    "yt_musicdata_df['channel_title'].replace(\"EnriqueIglesias\",\"Enrique Iglesias\")\n",
    "yt_musicdata_df['channel_title'].replace(\"ChildishGambino\",\"Childish Gambino\")\n",
    "yt_musicdata_df['channel_title'].replace(\"SamSmithWorld\",\"Sam Smith\")\n",
    "yt_musicdata_df['channel_title'].replace(\"MeghanTrainor\",\"Meghan Trainor\")\n",
    "yt_musicdata_df['channel_title'].replace(\"johnmayer\",\"John Mayer\")\n",
    "yt_musicdata_df['channel_title'].replace(\"weezer\",\"Weezer\")\n",
    "yt_musicdata_df['channel_title'].replace(\"AzealiaBanks\",\"Azealia Banks\")\n",
    "yt_musicdata_df['channel_title'].replace(\"Maroon5\",\"Maroon 5\")\n",
    "yt_musicdata_df['channel_title'].replace(\"Zayn\",\"ZAYN\")\n",
    "yt_musicdata_df['channel_title'].replace(\"ArianaGrande\",\"Ariana Grande\")\n",
    "yt_musicdata_df['channel_title'].replace(\"CAguilera\",\"Christina Aguilera\")\n",
    "yt_musicdata_df['channel_title'].replace(\"LadyGaga\",\"Lady Gaga\")\n",
    "yt_musicdata_df['channel_title'].replace(\"ToniBraxton\",\"Toni Braxton\")\n",
    "yt_musicdata_df['channel_title'].replace(\"JasonAldean\",\"Jason Aldean\")\n",
    "yt_musicdata_df['channel_title'].replace(\"PTXofficial\",\"PTX\")\n",
    "yt_musicdata_df['channel_title'].replace(\"KeithUrban\",\"Keith Urban\")\n",
    "yt_musicdata_df['channel_title'].replace(\"KaceyMusgraves\",\"Kacey Musgraves\")\n",
    "yt_musicdata_df['channel_title'].replace(\"ChrisStapleton\",\"Chris Stapleton\")\n",
    "yt_musicdata_df['channel_title'].replace(\"ThirtySecondsToMars\",\"Thirty Seconds To Mars\")\n",
    "\n",
    "# Clean Special Characters to prevent latin-1 encoding errors. Went back up to the pd.read_csv\n",
    "# and added \"encoding=\"utf-8\"\n",
    "\n",
    "yt_musicdata_df['video_title'] = [x.replace(\"é\",\"e\") for x in yt_musicdata_df['video_title']]\n",
    "yt_musicdata_df['video_title'] = [x.replace(\"ú\",\"u\") for x in yt_musicdata_df['video_title']]\n",
    "yt_musicdata_df['video_title'] = [x.replace(\"®\",\"\") for x in yt_musicdata_df['video_title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yt_musicdata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category_id_title_df to MySQL with Pandas\n",
    "yt_musicdata_df.to_sql('yt_statistics', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways in this notebook to pull the data directly from MySQL database\n",
    "# Method 1) Use SQL Alchemy Engine - Result: successfully reads from MySQL Database:\n",
    "engine.execute(\"SELECT * FROM yt_statistics\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2) Read from MySQL database using Pandas - Result: Success! - This method is a better setup for analysis.\n",
    "# The index column is automatically generated.\n",
    "yt_stat_df = pd.read_sql_query('SELECT * FROM yt_statistics', con=engine)\n",
    "yt_stat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2c) ETL on the \"Spotify Top 2018 Songs\" dataset:\n",
    "### Extraction, transformation, load, and read using 2 methods from MySQL Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify 2018 - Top 100 Songs - Raw CSV\n",
    "\n",
    "csv_file_spotify2018 = \"./resources/spotify_top2018.csv\"\n",
    "spotify2018_rawdata_df = pd.read_csv(csv_file_spotify2018)\n",
    "spotify2018_rawdata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify2018_rawdata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spotify DataFrame\n",
    "spotify_2018_id = spotify2018_rawdata_df['id']\n",
    "spotify_2018_name = spotify2018_rawdata_df['name']\n",
    "spotify_2018_artists = spotify2018_rawdata_df['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify2018_filtered_df = pd.DataFrame({\n",
    "            \"artists\": spotify_2018_artists,\n",
    "            \"song_name\": spotify_2018_name,\n",
    "            \"spotify_unique_id\": spotify_2018_id\n",
    "             })\n",
    "spotify2018_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category_id_title_df to MySQL with Pandas\n",
    "spotify2018_filtered_df.to_sql('spotify_2018top100_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two ways in this notebook to pull the data directly from MySQL database\n",
    "# Method 1) Use SQL Alchemy Engine - Result: successfully reads from MySQL Database:\n",
    "engine.execute(\"SELECT * FROM spotify_2018top100_data\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2) Read from MySQL database using Pandas - Result: Success! - This method is a better setup for analysis.\n",
    "# The index column is automatically generated.\n",
    "spotify_df = pd.read_sql_query('SELECT * FROM spotify_2018top100_data', con=engine)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3) Investigating how many of Spotify Top Artists that also had Top Trending Videos on YouTube in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Alchemy\n",
    "j = yt_statistics.join(yt_categories, yt_statistics.c.category_id == yt_categories.c.category_id)\n",
    "stmt = select([yt_statistics]).select_from(j)\n",
    "result = conn.execute(stmt)\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yt_merged2_df = pd.merge(yt_stat_df, yt_cat_df, how='inner', on='category_id',\n",
    "         left_index=False, right_index=False, sort=False)\n",
    "yt_merged2_df.insert(4, \"artist\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested loop to identify which artists from Spotify's Top 100 also had Top Trending Videos in 2018:\n",
    "# Loop through both YouTube and Spotify Data Sets, Normalize them (lower case and remove spaces),\n",
    "# and fill in the newly \"Artist\" column in the YouTube DF with the Spotify Artist Value if the artist name is found\n",
    "\n",
    "for index, x in yt_merged2_df.iterrows():\n",
    "    stryt = x['channel_title'].lower().replace(\" \", \"\")\n",
    "#     yt_musicdata_df['Artist'][index] = \n",
    "#     print(x['Channel Title'], \" | \", stryt)\n",
    "    \n",
    "    for y in spotify_df['artists'].unique():\n",
    "        str = y.lower().replace(\" \", \"\")\n",
    "        #print(y, \" | \", str)\n",
    "        if str in stryt:\n",
    "            yt_merged2_df['artist'][index] = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_merged2_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for only the Spotify's 2018 Top 100 Artists that also made it\n",
    "# on YouTube's Top Trending Videos in 2018 in the Music Category \n",
    "\n",
    "yt_merged2_df = yt_merged2_df.loc[yt_merged2_df['artist'] != '']\n",
    "yt_merged2_df = yt_merged2_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please view the \"artist\" column next to teh channel title\n",
    "yt_merged2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Count and store in results\n",
    "results = yt_merged2_df.groupby('artist').count()['channel_title'].sort_values(ascending=False)\n",
    "\n",
    "# Store results into a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Rename Columns\n",
    "results_df = results_df.rename(columns={\"channel_title\":\"top_trending_YT_videos_ct\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
