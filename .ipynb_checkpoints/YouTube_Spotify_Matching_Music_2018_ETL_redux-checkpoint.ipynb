{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube & Spotify Top Music Artists From 2018\n",
    "\n",
    "## SCOPE:\n",
    "### - Extracted, transformed, and loaded up YouTube's Top Trending Videos from December 2017 thru May 2018 for their videos categorized as music only, and created an \"Artist\" column to enable joining with Spotify's Top 100 Songs of 2018. Both dataframes were loaded into MySQL.\n",
    "\n",
    "\n",
    "## PURPOSE:\n",
    "### - I choose this project because I'm a avid listener and a huge music and concert goer, and wanted to work with data that I was familiar with.\n",
    "\n",
    "### Data Sources - Kaggle\n",
    " - https://www.kaggle.com/datasnaek/youtube-new/downloads/youtube-new.zip/114\n",
    " - https://www.kaggle.com/nadintamer/top-spotify-tracks-of-2018\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies:\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import simplejson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import string\n",
    "from sqlalchemy import create_engine, Column, Integer, String, join\n",
    "from sqlalchemy_utils import database_exists, create_database, drop_database, has_index\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rds_connection_string = \"<inser user name>:<insert password>@127.0.0.1/customer_db\"\n",
    "rds_connection_string = \"root:gREATNESS23$@127.0.0.1/\" #youtube_spotify_2018_db\"\n",
    "engine = create_engine(f'mysql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_spotify_2018_db2 database already exists in MySQL. Do you want you drop the table? Enter exactly: \"y\" or \"n\".y\n",
      "Database youtube_spotify_2018_db2 was dropped\n",
      "Do you want to create another database called: youtube_spotify_2018_db2?y\n",
      "The database youtube_spotify_2018_db2 was created Next You will need to create tables for this database.\n"
     ]
    }
   ],
   "source": [
    "# Use SQL Alchemy to search all of my databases in MySQL:\n",
    "\n",
    "# Can set up an input for the db_name later (optional)\n",
    "db_name = 'youtube_spotify_2018_db2'\n",
    "\n",
    "db_exist = database_exists(f'mysql://{rds_connection_string}youtube_spotify_2018_db2')\n",
    "db_url = f'mysql://{rds_connection_string}youtube_spotify_2018_db2'\n",
    "\n",
    "if db_exist == True:\n",
    "    drop_table_y_or_n = input(f'\"{db_name}\" database already exists in MySQL. Do you want you drop the table? Enter exactly: \"y\" or \"n\".  ')\n",
    "    if drop_table_y_or_n == 'y':\n",
    "        drop_database(db_url)\n",
    "        print(f\"Database {db_name} was dropped\")\n",
    "        create_new_db = input(f\"Do you want to create another database called: {db_name}?  \")\n",
    "        if create_new_db == 'y':\n",
    "            create_database(db_url)\n",
    "            print(f\"The database {db_name} was created Next You will need to create tables for this database.  \")\n",
    "        else:\n",
    "            print(\"No database was created. Goodbye!  \")\n",
    "    else:\n",
    "        print(\"The database exists. No action was taken. Goodbye!  \")\n",
    "else:\n",
    "    create_database(db_url)\n",
    "    print(f\"The queried database did not exist, and was created as: {db_name} .  \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Transform all of YouTube Top Trending Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube data has two parts: 1) Categories information in JSON format\n",
    "                            # 2) Top Trending US YouTube Videos in a CSV file\n",
    "\n",
    "# Part 1) YouTube Categories are seperated in a json file\n",
    "yt_json_file = './resources/youtube_US_category_id.json'\n",
    "yt_rawjson_df = pd.read_json(yt_json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the category id and category titles, and set them into a list\n",
    "\n",
    "# for i in yt_rawjson_df['items']:\n",
    "#     #print(i['id'])\n",
    "#     print(i['id'] + ' | ' + i['snippet']['title'])\n",
    "    \n",
    "\n",
    "category_id = [i['id'] for i in yt_rawjson_df['items']]\n",
    "category_title = [i['snippet']['title'] for i in yt_rawjson_df['items']]\n",
    "\n",
    "# Create a dataframe of the category id and title for later use\n",
    "category_id_title_df = pd.DataFrame({'category_id': category_id, 'category_title': category_title})\n",
    "category_id_title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1) is the YouTube Top US Videos in a CSV\n",
    "csv_file_yt = \"./resources/youtube_USvideos.csv\"\n",
    "yt_rawdata_df = pd.read_csv(csv_file_yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view rows, count and datatypes\n",
    "yt_rawdata_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "yt_cleandata_df = yt_rawdata_df.rename(columns={\"video_id\":\"Video ID\", \"trending_date\":\"Trending Date\",\n",
    "                                                \"title\":\"Title\", \"channel_title\":\"Channel Title\",\n",
    "                                                \"category_id\":\"Category Titles\", \"publish_time\":\"Publish Time\",\n",
    "                                                \"tags\":\"Tags\", \"views\":\"Views\",\n",
    "                                                \"likes\":\"Likes\", \"dislikes\":\"Dislikes\", \n",
    "                                                \"comment_count\":\"Comment Count\", \"thumbnail_link\":\"Thumbnail Link\",\n",
    "                                                \"comments_disabled\":\"Comments Disabled\", \"ratings_disabled\":\"Ratings Disabled\",\n",
    "                                                \"video_error_or_removed\":\"Video Error Or Removed\", \"description\":\"Description\"\n",
    "                                               })\n",
    "yt_cleandata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cells with Missing Information\n",
    "yt_cleandata_df = yt_cleandata_df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Dulplicates and Sort by Trending Date\n",
    "yt_cleandata_df.drop_duplicates(['Video ID', 'Trending Date', 'Title', 'Channel Title', 'Category Titles', 'Publish Time']).sort_values(by=['Trending Date'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Unwanted Columns\n",
    "\n",
    "to_drop =['Publish Time', 'Tags', 'Thumbnail Link', 'Comments Disabled', 'Ratings Disabled', 'Video Error Or Removed', 'Description']\n",
    "\n",
    "yt_cleandata_df.drop(to_drop, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the \".\" in Trending Date to \"-\"\n",
    "\n",
    "yt_cleandata_df['Trending Date'] = [x.replace(\".\",\"-\") for x in yt_cleandata_df['Trending Date']]\n",
    "yt_cleandata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
